# ################################
# Testing configuration for MFA-TDNN
# Modified from the file for ECAPA-TDNN, original authors:
# Authors: Hwidong Na 2020
#          Mirco Ravanelli 2020
# ################################

# tianchi added
num_of_channels: 512 #1024 #512
num_of_combined_channels: 1536 #3072 #1536
att_channels: 640
input_res2net_scale: 4
c_1st_conv: 32
test_len: 7
# att_layer_channels: [16, 64, 64, 64] 

seed: 2021
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Folders and train_log file
voxceleb_source: /home/tianchi/data/VoxCeleb/
data_folder: /home/tianchi/data/VoxCeleb/voxceleb2
output_folder: !ref results/tr_ecapa_tc_0813/channel<num_of_channels>/seed<seed>/test_tzbz8
# output_folder: !ref results/tr_ecapa_tc_0813/channel<num_of_channels>/seed<seed>/test_tzbz8_h
# output_folder: !ref results/tr_ecapa_tc_0813/channel<num_of_channels>/seed<seed>/test_tzbz8_e
# output_folder: !ref results/tr_ecapa_tc_0813/channel<num_of_channels>/seed<seed>/len<test_len>_test_tzbz8



save_folder: !ref <output_folder>/save/
device: 'cuda:0'

# Use the following links for the official voxceleb splits:
# VoxCeleb1 (cleaned): https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test2.txt
# VoxCeleb1-H (cleaned): https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_hard2.txt
# VoxCeleb1-E (cleaned): https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_all2.txt
# VoxCeleb1-E and VoxCeleb1-H lists are drawn from the VoxCeleb1 training set.
# Therefore you cannot use any files in VoxCeleb1 for training if you are using these lists for testing.

verification_file: https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test2.txt #
# verification_file: https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_hard2.txt # _h
# verification_file: https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_all2.txt  # _e

pretrain_path: !ref results/tr_ecapa_tc_0813/channel<num_of_channels>/seed<seed>/save/CKPT+2021-08-17+18-17-50+00/ # channel 512 seed 2021 


# csv files
train_data: !ref <save_folder>/train.csv
enrol_data: !ref <save_folder>/enrol.csv
test_data: !ref <save_folder>/test.csv

batch_size: 8
score_norm: 's-norm' # z-norm t-norm s-norm none
cohort_size: 20000 # amount of imposter utterances in normalization cohort
n_train_snts: 400000 # used for normalization stats

# Feature parameters
n_mels: 80
left_frames: 0
right_frames: 0
deltas: False

# Dataloader options
train_dataloader_opts:
    batch_size: !ref <batch_size>

enrol_dataloader_opts:
    batch_size: !ref <batch_size>

test_dataloader_opts:
    batch_size: !ref <batch_size>

compute_features: !new:speechbrain.lobes.features.Fbank
    n_mels: !ref <n_mels>

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: sentence
    std_norm: False
embedding_model: !new:speechbrain.lobes.models.ECAPA_tc_0813.ECAPA_tc_0813
    input_res2net_scale: !ref <input_res2net_scale>
    c_1st_conv: !ref <c_1st_conv>
    input_size: !ref <n_mels>
    channels: [!ref <att_channels>, !ref <num_of_channels>, !ref <num_of_channels>, !ref <num_of_channels>, !ref <num_of_combined_channels>]
    kernel_sizes: [5, 3, 3, 3, 1]
    dilations: [1, 2, 3, 4, 1]
    attention_channels: 128
    lin_neurons: 192

mean_var_norm_emb: !new:speechbrain.processing.features.InputNormalization
    norm_type: global
    std_norm: False

pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
    collect_in: !ref <save_folder>
    loadables:
        embedding_model: !ref <embedding_model>
    paths:
        embedding_model: !ref <pretrain_path>/embedding_model.ckpt
